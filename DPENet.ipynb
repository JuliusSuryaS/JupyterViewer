{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DPENet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from time import sleep\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Input and GT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GT format  \n",
    "- ['ego_global_x', 'ego_global_y']  \n",
    "\n",
    "Input format  \n",
    "- ['ego_vx', 'yaw_rate', 'sas_angle', 'long_acc', 'lat_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt_folder = './DDPE_GT_adaf_1/'\n",
    "in_folder = './DDPE_input_adaf_1/'\n",
    "gt_file_list = glob.glob(gt_folder+'/*_gt.json')\n",
    "gt_file_list.sort()\n",
    "in_train, gt_train = [], []\n",
    "in_test, gt_test = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "795ef7dd10724b698593afec7da46d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "folder progress:   0%|          | 0/533745 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the json log.\n",
    "for k in trange(len(gt_file_list),desc='folder progress'):\n",
    "    # Load the GT\n",
    "    file_name_gt = gt_file_list[k]\n",
    "    with open(file_name_gt, 'r', encoding='utf-8-sig') as data_file_gt:\n",
    "        try:\n",
    "            data_gt = json.load(data_file_gt)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Load the input\n",
    "    file_name_in = in_folder + gt_file_list[k][17:26] + '_in.json'\n",
    "    with open(file_name_in, 'r', encoding='utf-8-sig') as data_file_in:\n",
    "        try:\n",
    "            data_in = json.load(data_file_in)\n",
    "        except:\n",
    "            continue\n",
    "    if k % 10 == 0:\n",
    "        gt_test.append([data_gt['ego_global_x'], data_gt['ego_global_y']])\n",
    "        in_test.append([data_in['ego_vx'],data_in['yaw_rate'],data_in['sas_angle'],data_in['long_acc'],data_in['lat_acc']])\n",
    "    else:\n",
    "        gt_train.append([data_gt['ego_global_x'], data_gt['ego_global_y']])\n",
    "        in_train.append([data_in['ego_vx'],data_in['yaw_rate'],data_in['sas_angle'],data_in['long_acc'],data_in['lat_acc']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make list to tensor\n",
    "gt_train = torch.tensor(gt_train).cuda()\n",
    "in_train = torch.tensor(in_train).cuda()\n",
    "gt_test = torch.tensor(gt_test).cuda()\n",
    "in_test = torch.tensor(in_test).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class to use the dataloader\n",
    "class DPEDataset(data.Dataset):\n",
    "    def __len__(self):\n",
    "        return len(in_train)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        in_tmp = in_train[idx]\n",
    "        gt_tmp = gt_train[idx]\n",
    "        return {'in':in_tmp,'gt':gt_tmp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DPETestset(data.Dataset):\n",
    "    def __len__(self):\n",
    "        return len(in_test)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        in_tm = in_test[idx]\n",
    "        gt_tm = gt_test[idx]\n",
    "        return {'in':in_tm,'gt':gt_tm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dpe_dataset = DPEDataset()\n",
    "dpe_testset = DPETestset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(gt_train), len(in_train), len(gt_test), len(in_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get lateral point from the polynomial equation\n",
    "# input \n",
    "# : longitudinal distance, C1, C2, C3\n",
    "# output \n",
    "# : lateral point x\n",
    "\n",
    "def get_x_polynomial(long_dist, C1, C2, C3):\n",
    "    mean = 0.0\n",
    "    inv_sigma = 1.0\n",
    "    y_ = (long_dist-mean) * inv_sigma\n",
    "    \n",
    "    x = C1 * (y_**1) + C2 * (y_**2) + C3 * (y_**3)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MSELoss from lateral point\n",
    "# input\n",
    "# : [C1, C2, C3], gt['ego_global_x', 'ego_global_y']\n",
    "# output\n",
    "# : sum, variance, standard deviation of MSELoss\n",
    "\n",
    "def lp_loss(output, gt):\n",
    "    criterion = nn.MSELoss()\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    mse_total = []\n",
    "    mse_mean, mse_var, mse_std = 0.0, 0.0, 0.0\n",
    "    for i in range(len(gt[0][1])):\n",
    "        x_tmp = get_x_polynomial(gt[0][1][i],output[0][0],output[0][1],output[0][2])\n",
    "        # make to tensor if needed\n",
    "        x_tmp_torch = x_tmp\n",
    "        gt_tmp_torch = gt[0][0][i]\n",
    "        \n",
    "        mse_tmp = criterion(x_tmp_torch,gt_tmp_torch)\n",
    "        mse_total.append(mse_tmp)\n",
    "    mse_mean = torch.mean(torch.tensor(mse_total))\n",
    "    mse_var = torch.var(torch.tensor(mse_total))\n",
    "    mse_std = torch.std(torch.tensor(mse_total))\n",
    "    \n",
    "    return mse_mean, mse_var, mse_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DPENet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DPENet\n",
    "# input\n",
    "# : CAN information (ego_vx, yaw_rate, sas_angle, long_acc, lat_acc)\n",
    "# output\n",
    "# : variable for polynomial equation (C1, C2, C3)\n",
    "\n",
    "# construct model on cuda if available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "class DPENet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DPENet,self).__init__()\n",
    "        # fullyconncted layer\n",
    "        fc1 = nn.Linear(5,10,bias=True)\n",
    "        fc2 = nn.Linear(10,10,bias=True)\n",
    "        fc3 = nn.Linear(10,10,bias=True)\n",
    "        fc4 = nn.Linear(10,10,bias=True)\n",
    "        fc5 = nn.Linear(10,10,bias=True)\n",
    "        fc6 = nn.Linear(10,10,bias=True)\n",
    "        fc7 = nn.Linear(10,10,bias=True)\n",
    "        fc8 = nn.Linear(10,10,bias=True)\n",
    "        fc9 = nn.Linear(10,10,bias=True)\n",
    "        fc10 = nn.Linear(10,3,bias=True)\n",
    "        tanh = nn.Tanh()\n",
    "        dropout = nn.Dropout(0.3)\n",
    "        #self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc_module = nn.Sequential(\n",
    "            fc1,\n",
    "            tanh,\n",
    "            fc2,\n",
    "            tanh,\n",
    "            fc3,\n",
    "            tanh,\n",
    "            fc4,\n",
    "            tanh,\n",
    "            fc5,\n",
    "            tanh,\n",
    "            fc6,\n",
    "            tanh,\n",
    "            fc7,\n",
    "            tanh,\n",
    "            fc8,\n",
    "            tanh,\n",
    "            fc9,\n",
    "            tanh,\n",
    "            fc10\n",
    "        )\n",
    "        # use gpu\n",
    "        if use_cuda:\n",
    "            self_fc_module = self.fc_module.cuda()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.fc_module(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(DPENet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Xavier Normal initialization\n",
    "def weight_init(m): \n",
    "    if isinstance(m, nn.Linear):\n",
    "        size = m.weight.size()\n",
    "        fan_out = size[0] # number of rows\n",
    "        fan_in = size[1] # number of columns\n",
    "        variance = np.sqrt(2.0/(fan_in + fan_out))\n",
    "        m.weight.data.normal_(0.0, variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# argument\n",
    "# learning rate and beta1,2 for optimizer\n",
    "dpenet_learning_rate = 0.01 # 0.01(x) 0.001 0.0002\n",
    "dpenet_momentum = 0.9\n",
    "dpenet_beta1 = 0.5\n",
    "dpenet_beta2 = 0.999\n",
    "# lambda for loss\n",
    "lambda_mean = 10**-10\n",
    "lambda_var = 10**-10\n",
    "lambda_std = 10**-10\n",
    "# number of epoch and log steo\n",
    "num_epochs = 1000\n",
    "log_step = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataloader\n",
    "data_loader = data.DataLoader(dataset=dpe_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=dpe_testset, batch_size=1)\n",
    "\n",
    "# tensorboardX summary\n",
    "summary = SummaryWriter('log')\n",
    "dpenet = DPENet()\n",
    "dpenet.apply(weight_init)\n",
    "\n",
    "# To make graph in summary\n",
    "dummmy = torch.zeros(5)\n",
    "summary.add_graph(dpenet,dummmy.cuda())\n",
    "\n",
    "# Optimizer\n",
    "dpenet_optimizer = optim.Adam(dpenet.parameters(), lr=dpenet_learning_rate)\n",
    "#dpenet_optimizer = optim.Adam(dpenet.parameters(), dpenet_learning_rate, [dpenet_beta1, dpenet_beta2])\n",
    "#dpenet_optimizer = optim.SGD(dpenet.parameters(), lr=dpenet_learning_rate, momentum=dpenet_momentum)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, sample in enumerate(data_loader):\n",
    "        \n",
    "        # input : ['ego_vx', 'yaw_rate', 'sas_angle', 'long_acc', 'lat_acc']\n",
    "        # gt : ['ego_global_x', 'ego_global_y']\n",
    "        input_ = sample['in'].cuda()\n",
    "        gt_ = sample['gt']\n",
    "        output_ = dpenet(input_)\n",
    "        #print(output_)\n",
    "        # train dpenet\n",
    "        # reset the gradient for the optimizer\n",
    "        # zero_grad : 역전파 실행 전 변화도 0으로\n",
    "        dpenet_optimizer.zero_grad()\n",
    "        \n",
    "        # loss from lateral position\n",
    "        loss_lp_mean, loss_lp_var, loss_lp_std = lp_loss(output_,gt_)\n",
    "        loss = lambda_mean*loss_lp_mean + lambda_var*loss_lp_var + lambda_std*loss_lp_std\n",
    "        loss = Variable(loss, requires_grad=True)\n",
    "        # backpropagate the gradient\n",
    "        loss.backward()\n",
    "        # update the weights using the gradient with the optimizer\n",
    "        dpenet_optimizer.step()\n",
    "        \n",
    "        # print the log information\n",
    "        if (i+1) % log_step == 0:\n",
    "            print('Epoch [%d/%d], BatchStep[%d/%d]' % (epoch + 1, num_epochs, i + 1, len(in_train)))\n",
    "            print('Loss: %.4f, lp_mean: %.4f, lp_var: %.4f, lp_std: %.4f' \n",
    "                  % (loss.data, loss_lp_mean.data, loss_lp_var.data, loss_lp_std.data))\n",
    "\n",
    "    loss_test = 0\n",
    "    loss_test_lsit = []\n",
    "    with torch.no_grad():\n",
    "        for i, sample_t in enumerate(test_loader):\n",
    "            input_t = sample_t['in'].cuda()\n",
    "            gt_t = sample_t['gt']\n",
    "            output_t = dpenet(input_t)\n",
    "            loss_lp_mean_t, loss_lp_var_t, loss_lp_std_t = lp_loss(output_t,gt_t)\n",
    "            loss_test_lsit.append(loss_lp_mean_t)\n",
    "            \n",
    "    loss_test = torch.mean(torch.tensor(loss_test_lsit))\n",
    "    print('Epoch [%d/%d]' % (epoch + 1, num_epochs))\n",
    "    print('Test Loss: %.4f' % (loss_test.data))\n",
    "\n",
    "    # visualize the parameter\n",
    "    for name, param in dpenet.named_parameters():\n",
    "        #summary.add_histogram(name, param, epoch)\n",
    "        summary.add_histogram(name, param.clone().cpu().data.numpy(), epoch, bins='doane')\n",
    "    \n",
    "    # save summary\n",
    "    summary.add_scalar('loss/loss', loss.item(), epoch)\n",
    "    summary.add_scalar('loss/loss_lp_mean', loss_lp_mean.item(), epoch)\n",
    "    summary.add_scalar('loss/loss_lp_var', loss_lp_var.item(), epoch)\n",
    "    summary.add_scalar('loss/loss_lp_std', loss_lp_std.item(), epoch)\n",
    "    summary.add_scalar('loss_t/loss', loss_test.item(), epoch)\n",
    "    \n",
    "    summary.flush()\n",
    "    # save the model parameters\n",
    "    #if epoch % 10 == 0:\n",
    "    model_path = os.path.join('./DPENet_model', 'DPENet-%d.pkl' % (epoch + 1))\n",
    "    torch.save(dpenet.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with \n",
    "epoch [1/1000] Test Loss: 236042076160.0000\n",
    "epoch [2/1000] Test Loss: 238885634048.0000 \n",
    "Epoch [3/1000] Test Loss: 235835916288.0000\n",
    "Epoch [4/1000] Test Loss: 237683245056.0000\n",
    "Epoch [5/1000] Test Loss: 240484368384.0000\n",
    "Epoch [6/1000] Test Loss: 235287920640.0000\n",
    "Epoch [7/1000] Test Loss: 232444411904.0000\n",
    "Epoch [8/1000] Test Loss: 233658007552.0000\n",
    "Epoch [9/1000] Test Loss: 235095965696.0000\n",
    "Epoch [10/1000] Test Loss: 232347713536.0000\n",
    "Epoch [11/1000] Test Loss: 239848275968.0000\n",
    "Epoch [12/1000] Test Loss: 242579668992.0000\n",
    "Epoch [13/1000] Test Loss: 240169140224.0000\n",
    "Epoch [14/1000] Test Loss: 239437922304.0000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
